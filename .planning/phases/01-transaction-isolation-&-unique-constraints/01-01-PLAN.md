---
phase: 01-transaction-isolation-&-unique-constraints
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - upstream/services/payer_drift.py
  - upstream/tests.py
autonomous: true

must_haves:
  truths:
    - "Concurrent drift detection runs on same customer data do not create duplicate alerts"
    - "Database lock is acquired before drift computation begins"
    - "Lock is held until all DriftEvent records are created"
    - "Concurrent tasks for same customer wait rather than race"
  artifacts:
    - path: "upstream/services/payer_drift.py"
      provides: "Transaction-safe drift computation with customer row locking"
      contains: "select_for_update"
    - path: "upstream/tests.py"
      provides: "Test for concurrent drift detection behavior"
      contains: "test_concurrent_drift_detection"
  key_links:
    - from: "upstream/services/payer_drift.py"
      to: "Customer model"
      via: "select_for_update() lock"
      pattern: "Customer\\.objects\\.select_for_update\\(\\)"
---

<objective>
Add transaction isolation with select_for_update() to prevent race conditions in concurrent drift detection.

Purpose: Prevent duplicate DriftEvent creation when multiple Celery workers process the same customer's drift detection simultaneously. This is a critical data integrity issue for production systems with concurrent task processing.

Output: Updated payer_drift.py with customer row locking and a test validating concurrent behavior.
</objective>

<execution_context>
@/home/codespace/.claude/get-shit-done/workflows/execute-plan.md
@/home/codespace/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/01-transaction-isolation-&-unique-constraints/01-RESEARCH.md

# Key source files
@upstream/services/payer_drift.py
@upstream/models.py
@upstream/tasks.py
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add select_for_update() locking to compute_weekly_payer_drift</name>
  <files>upstream/services/payer_drift.py</files>
  <action>
Modify `compute_weekly_payer_drift()` to lock the customer row before computing drift:

1. At the start of the try block (before the `with transaction.atomic():`), add customer row locking:
   ```python
   try:
       with transaction.atomic():
           # Lock customer row to prevent concurrent drift computation
           # Other tasks for same customer will wait until this transaction commits
           locked_customer = Customer.objects.select_for_update().get(id=customer.id)

           # ... rest of existing code uses locked_customer instead of customer
   ```

2. The `select_for_update()` must be INSIDE the `transaction.atomic()` block to hold the lock.

3. Use the locked_customer reference throughout the function instead of the original customer parameter for all database operations.

4. Add a docstring note explaining the locking strategy:
   ```python
   """
   ...

   Concurrency:
       Uses select_for_update() to lock the customer row, preventing concurrent
       drift computations for the same customer from creating duplicate events.
       Other Celery tasks attempting to compute drift for the same customer will
       block until this transaction completes.
   """
   ```

Why this approach:
- Locking the customer row is simpler than a dedicated lock table
- Prevents concurrent computations without requiring IntegrityError handling
- Uses database-level locking which survives process crashes
- Transaction rolls back cleanly on failure, releasing locks
  </action>
  <verify>
Run `python manage.py check` to verify no Django errors.
Run `python -c "from upstream.services.payer_drift import compute_weekly_payer_drift; print('Import OK')"` to verify syntax is correct.
  </verify>
  <done>
compute_weekly_payer_drift() acquires customer row lock with select_for_update() before any drift event creation.
  </done>
</task>

<task type="auto">
  <name>Task 2: Add IntegrityError handling for DriftEvent creation</name>
  <files>upstream/services/payer_drift.py</files>
  <action>
Add defensive IntegrityError handling around DriftEvent.objects.create() calls as a second layer of protection (defense in depth):

1. Import IntegrityError at top of file:
   ```python
   from django.db import transaction, IntegrityError
   ```

2. Wrap each DriftEvent.objects.create() call in try/except IntegrityError:
   ```python
   try:
       DriftEvent.objects.create(
           customer=locked_customer,
           report_run=report_run,
           payer=payer,
           cpt_group=cpt_group,
           drift_type="DENIAL_RATE",
           # ... other fields
       )
       events_created += 1
   except IntegrityError:
       # Duplicate event already exists (race condition)
       # This is expected when unique constraint is added in migration 0014
       # Log and continue - duplicate prevention working as intended
       pass
   ```

3. Apply same pattern to both DENIAL_RATE and DECISION_TIME DriftEvent.objects.create() calls.

Why:
- Provides defense in depth - even if lock is somehow bypassed, duplicate creation fails gracefully
- Prepares code for unique constraint that will be added in Plan 02
- Follows Django best practice for idempotent record creation
  </action>
  <verify>
Run unit tests to ensure drift computation still works: `python manage.py test upstream.tests.DriftEventTests -v 2`
  </verify>
  <done>
Both DriftEvent.objects.create() calls wrapped in IntegrityError handling.
  </done>
</task>

<task type="auto">
  <name>Task 3: Add concurrent drift detection test</name>
  <files>upstream/tests.py</files>
  <action>
Add a test that validates the locking behavior prevents duplicate event creation.

Add to the DriftEventTests class in upstream/tests.py:

```python
from concurrent.futures import ThreadPoolExecutor
from django.db import connection
import threading

class DriftEventTests(TestCase):
    # ... existing tests ...

    def test_concurrent_drift_detection_prevents_duplicates(self):
        """
        Test that concurrent drift computations for same customer don't create duplicates.

        Validates DB-01: Transaction isolation for concurrent drift detection.
        """
        # Create customer with sufficient claims for drift detection
        customer = Customer.objects.create(name="Concurrent Test Customer")
        upload = Upload.objects.create(
            customer=customer,
            filename="concurrent_test.csv",
            status="success"
        )

        # Create claims that will trigger drift events
        from datetime import date, timedelta
        base_date = date.today()

        # Baseline period claims (high denial rate)
        for i in range(30):
            ClaimRecord.objects.create(
                customer=customer,
                upload=upload,
                payer="Test Payer",
                cpt="99213",
                cpt_group="E&M",
                submitted_date=base_date - timedelta(days=60 + i),
                decided_date=base_date - timedelta(days=55 + i),
                outcome="DENIED" if i % 2 == 0 else "PAID",
            )

        # Current period claims (different denial rate to trigger drift)
        for i in range(30):
            ClaimRecord.objects.create(
                customer=customer,
                upload=upload,
                payer="Test Payer",
                cpt="99213",
                cpt_group="E&M",
                submitted_date=base_date - timedelta(days=10 + i % 10),
                decided_date=base_date - timedelta(days=5 + i % 10),
                outcome="PAID",  # All paid = different rate
            )

        # Track results from concurrent executions
        results = []
        errors = []

        def run_drift_computation():
            try:
                # Each thread needs its own database connection
                from django.db import connection
                connection.ensure_connection()

                from upstream.services.payer_drift import compute_weekly_payer_drift
                report_run = compute_weekly_payer_drift(customer, min_volume=10)
                results.append(report_run)
            except Exception as e:
                errors.append(str(e))
            finally:
                connection.close()

        # Run drift computation concurrently in 3 threads
        threads = []
        for _ in range(3):
            t = threading.Thread(target=run_drift_computation)
            threads.append(t)
            t.start()

        for t in threads:
            t.join(timeout=30)

        # Verify no errors occurred
        self.assertEqual(len(errors), 0, f"Errors during concurrent execution: {errors}")

        # Verify we got results from all threads
        self.assertEqual(len(results), 3, "Expected 3 successful drift computations")

        # Key assertion: Despite 3 concurrent runs, total drift events should not have duplicates
        # Each report_run should have its own events, but for same customer/payer/cpt_group
        # the combination should be unique per report_run
        total_events = DriftEvent.objects.filter(customer=customer).count()

        # Count unique (report_run, payer, cpt_group, drift_type) combinations
        from django.db.models import Count
        unique_combinations = DriftEvent.objects.filter(
            customer=customer
        ).values(
            'report_run', 'payer', 'cpt_group', 'drift_type'
        ).annotate(count=Count('id'))

        # Each combination should appear exactly once (count=1)
        for combo in unique_combinations:
            self.assertEqual(
                combo['count'], 1,
                f"Duplicate drift event found: {combo}"
            )
```

Note: This test may need adjustment based on how locking actually serializes the operations. The key validation is that no duplicate events are created for the same (customer, report_run, payer, cpt_group, drift_type) combination.
  </action>
  <verify>
Run the new test: `python manage.py test upstream.tests.DriftEventTests.test_concurrent_drift_detection_prevents_duplicates -v 2`
  </verify>
  <done>
Test validates that concurrent drift detection does not create duplicate events.
  </done>
</task>

</tasks>

<verification>
1. All existing drift tests pass: `python manage.py test upstream.tests.DriftEventTests -v 2`
2. New concurrent test passes: `python manage.py test upstream.tests.DriftEventTests.test_concurrent_drift_detection_prevents_duplicates -v 2`
3. Django check passes: `python manage.py check`
4. Code contains select_for_update(): `grep -n "select_for_update" upstream/services/payer_drift.py`
5. Code contains IntegrityError handling: `grep -n "IntegrityError" upstream/services/payer_drift.py`
</verification>

<success_criteria>
- compute_weekly_payer_drift() acquires customer row lock before creating DriftEvent records
- IntegrityError is caught and handled gracefully for DriftEvent creation
- Test validates concurrent execution behavior
- All existing tests continue to pass
</success_criteria>

<output>
After completion, create `.planning/phases/01-transaction-isolation-&-unique-constraints/01-01-SUMMARY.md`
</output>
